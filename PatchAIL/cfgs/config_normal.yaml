defaults:
  - _self_
  - agent: potil
  - suite: dmc
  - override hydra/launcher: submitit_local

# Root Dir
root_dir: '/home/liumh/app/PatchIRL'

# replay buffer
replay_buffer_size: 1000000 # 150000
replay_buffer_num_workers: 2
nstep: 3
batch_size: 256 # 128
# misc
seed: 2
device: cuda
save_video: true
save_train_video: false
use_tb: true
algo_name: 'patchgail'
record_video: false

# experiment
obs_type: 'pixels' # pixels, features
reward_type: 'airl' # airl, gail, gail2
experiment: ${algo_name}_rewscale_${reward_scale}_numtraj_${num_demos}_${suite.name}_${obs_type}_${task_name}_seed_${seed}

# expert dataset
num_demos: 10 #50(openaigym), 10(dmc), 1(metaworld), 1(particle), 1(robotgym)
expert_dataset: '${root_dir}/PatchIRL/expert_demos/${suite.name}/${task_name}/expert_demos.pkl'

# Load weights
load_bc: false

# Weights
bc_weight: '${root_dir}/PatchIRL/weights/${suite.name}_${obs_type}/${task_name}/bc.pt'

# Train with BC loss
bc_regularize: false
bc_weight_type: 'linear' # linear, qfilter
bc_weight_schedule: 'linear(1.0,0.01,400000)'

# Reward scale
reward_scale: 1.0

hydra:
  run:
    dir: ./exp_local/${suite.name}_${task_name}/${algo_name}_${num_demos}/${experiment} # ${now:%H%M%S}_${experiment}
  sweep:
    dir: ./exp_local/${suite.name}_${task_name}/${algo_name}_${num_demos}/${now:%H%M%S}
    subdir: ${hydra.job.num}
  launcher:
    tasks_per_node: 1
    nodes: 1
    submitit_folder: ./exp/${suite.name}_${task_name}/${algo_name}_${num_demos}/${now:%H%M%S}_${experiment}/.slurm
